#!/usr/bin/python

import argparse
import logging as log
import glob
import string
import os

# Requires install of xlsxwriter: https://xlsxwriter.readthedocs.io/index.html
# To install, 'pip install xlsxwriter'
# This will install the package at default python library location. If no
# permission, use 'pip install --user xlsxwriter' to install for local user
# at the ~/.local/lib/python3.5/site-packages location. Then you must also
# make sure the PYTHONPATH environment variable is defined and uses this path
import xlsxwriter as xlsx

terminate = False

switch_stats_script = 'switch_stats.py'

log.basicConfig(format='%(asctime)s - [%(levelname)s]: %(message)s',
                datefmt='%m/%d/%Y %I:%M:%S %p', level=log.INFO)

parser = argparse.ArgumentParser(description='This script will analyze the output of a series of STATS '
                                 'files generated by %s. It will gather information about the top processes '
                                 'and CPU usage data and generate an xlsx file with the relavent data.'
                                 % switch_stats_script)
parser.add_argument('-d', '--directory',
                    help='Specify the directory to analyze logs from. (default to current directory).',
                    default='.')
parser.add_argument('-r', '--recurse', help='Recurse through directories looking for any stats files.',
                    default=False, action='store_true')
parser.add_argument('-v', '--verbose', help='Enable verbose logging',
                    default=False, action='store_true')
parser.add_argument('-p', '--pause', help='Enable debug mode to pause when done with a directory',
                    default=False, action='store_true')

args = parser.parse_args()

# Note on 'configs', 'tests', and 'sections':
# These are used to match the directory/filename in order to generate the
# appropriate workbook name and worksheet name and where to place data on
# the worksheet. It expects the configs to be located in a directory structure
# such at this: ./<section>-<config>-<test>/stats/<stats-files>
# example: 2core-8ls-chassisreboot/stats/<stats-files>
# If no matching pattern is found, will default to results.xlsx
configs = ['default', '4ls', '8ls', '16ls']
tests = ['default', 'chassisreboot', 'hafailover', 'hcl', 'idle', 'supportsave', 'switchdisable', 'switchenable']
sections = ['2core', '4core']
groups = ['Average', 'Instantaneous']
group_row_offset = 20		    # Give outselves 20 rows for the group summary/chart
data_row_offset = group_row_offset * len(groups)

default_column_width = 7.57     # 8.43 excel default... make ours a bit smaller
default_x_scale = 1.23		    # make our charts a little bit bigger
default_y_scale = 1.38

workbooks = {}
worksheets = {}

# Search data represents the patterns to look for in a given stats file. This
# will output a spreadsheet with the recorded stats from a stats analysis run.
# The filename will be 'results_<id>.xlsx where <id> is one of *configs* above.
# There will be multiple worksheets created upon need where the worksheet name
# is one of *tests* above.
#
# Each worksheet will consist of upto two sections where each section is one of
# *sections* above. These sections will be broken up vertically with
# section 0 starting in Column A, and section 1 starting in Column <X> where <x>
# is 1 plus the number of elements in *search_data* below. Example, if there
# were 5 elements in *search_data*, then section 1 would start in Column G.
#
# Each section will be broken up into two groups where each group is one of
# *groups* above. These groups will be split up horizontally with group
# 0 starting in Row 0, and group 1 starting in *group_row_offset* as defined above
#
# An exmaple spreadsheet will look something like this
# +----------------------------------+----------------------------------+
# | Section 0 - Group 0              | Section 1 - Group 0              |
# | Summary +-----------------------+| Summary +-----------------------+|
# | Info    |                       || Info    |                       ||
# |         |   Chart               ||         |   Chart               ||
# |         |                       ||         |                       ||
# |         +-----------------------+|         +-----------------------+|
# +----------------------------------+----------------------------------+
# | Section 0 - Group 1              | Section 1 - Group 1              |
# | Summary +-----------------------+| Summary +-----------------------+|
# | Info    |                       || Info    |                       ||
# |         |   Chart               ||         |   Chart               ||
# |         |                       ||         |                       ||
# |         +-----------------------+|         +-----------------------+|
# +----------------------------------+----------------------------------+
# | Data Output                                                         |
# | ...                                                                 |
# |                                                                     |
# +---------+---------+-------------------------------------------------+
# | [test0] | [test1] | [test2] ...                                     |
# +---------+---------+-------------------------------------------------+
#
# Required fields are
# { 'header'	: '<string>' }	This is the string to write to the header column
# { 'pattern'	: '<string>' }	This is the string pattern to match on the line
#
# Optional fields are
# { 'field-idx' : <int> }		Only look for the pattern at this field position
# { 'exclude-pattern' : <bool> }Strip off the pattern when writing the output
# { 'occurance' : <int> }		Only consider the <int>'th 'top' output
# { 'type' : '<type>' }			Can be int|float to determine cell format
# { 'summary-group' : <int> }	Include the min/max/average in summary info
# { 'chart-group' : <int> }		Include this field as a series in the group chart
# { 'column-width' : <float>	Set the width of this column in the spreadsheet
# { 'next-line' : <bool> }		Output 'field-idx' on next line when pattern found

search_data = [
    {
        'header'			: 'Time',
        'pattern'			: 'UTC',
        'field-idx'			: 3,
        'column-width'		: 13.57
    }, {
        'header'			: 'Avg-Usr',
        'pattern'			: '%us,',
        'exclude-pattern'	: True,
        'occurance'			: 1,
        'type'				: 'float',
        'summary-group'		: 0,
        'chart-group'		: 0,
    }, {
        'header'			: 'Avg-Sys',
        'pattern'			: '%sy,',
        'exclude-pattern'	: True,
        'occurance'			: 1,
        'type'				: 'float',
        'summary-group'		: 0,
        'chart-group'		: 0,
    }, {
        'header'			: 'Avg-Idle',
        'pattern'			: '%id,',
        'exclude-pattern'	: True,
        'occurance'			: 1,
        'type'				: 'float',
        'summary-group'		: 0,
        'chart-group'		: 0,
    }, {
        'header'			: 'Avg-Wait',
        'pattern'			: '%wa,',
        'exclude-pattern'	: True,
        'occurance'			: 1,
        'type'				: 'float',
        'summary-group'		: 0,
        'chart-group'		: 0,
    }, {
        'header'			: 'Avg-ESMd%',
        'pattern'			: 'esmd',
        'occurance'			: 1,
        'field-idx'			: 8,
        'type'				: 'int',
        'summary-group'		: 0,
        'chart-group'		: 0,
    }, {
        'header'			: 'Avg-Weblinker%',
        'pattern'			: 'weblinker',
        'occurance'			: 1,
        'field-idx'			: 8,
        'type'				: 'int',
        'summary-group'		: 0,
        'chart-group'		: 0,
    }, {
        'header'			: 'Avg-MDD%',
        'pattern'			: 'mdd',
        'occurance'			: 1,
        'field-idx'			: 8,
        'type'				: 'int',
        'summary-group'		: 0,
        'chart-group'		: 0,
    }, {
        'header'			: 'Inst-Usr',
        'pattern'			: '%us,',
        'exclude-pattern'	: True,
        'occurance'			: 2,
        'type'				: 'float',
        'summary-group'		: 1,
        'chart-group'		: 1,
    }, {
        'header'			: 'Inst-Sys',
        'pattern'			: '%sy,',
        'exclude-pattern'	: True,
        'occurance'			: 2,
        'type'				: 'float',
        'summary-group'		: 1,
        'chart-group'		: 1,
    }, {
        'header'			: 'Inst-Idle',
        'pattern'			: '%id,',
        'exclude-pattern'	: True,
        'occurance'			: 2,
        'type'				: 'float',
        'summary-group'		: 1,
        'chart-group'		: 1,
    }, {
        'header'			: 'Inst-Wait',
        'pattern'			: '%wa,',
        'exclude-pattern'	: True,
        'occurance'			: 2,
        'type'				: 'float',
        'summary-group'		: 1,
        'chart-group'		: 1,
    }, {
        'header'			: 'Inst-ESMd%',
        'pattern'			: 'esmd',
        'occurance'			: 2,
        'field-idx'			: 8,
        'type'				: 'int',
        'summary-group'		: 1,
        'chart-group'		: 1,
    }, {
        'header'			: 'Inst-Weblinker%',
        'pattern'			: 'weblinker',
        'occurance'			: 2,
        'field-idx'			: 8,
        'type'				: 'int',
        'summary-group'		: 1,
        'chart-group'		: 1,
    }, {
        'header'			: 'Inst-MDD%',
        'pattern'			: 'mdd',
        'occurance'			: 2,
        'field-idx'			: 8,
        'type'				: 'int',
        'summary-group'		: 1,
        'chart-group'		: 1,
    }, {
        'header'			: 'Top-Proc',
        'pattern'			: 'PID',
        'field-idx'			: 11,
        'next-line'			: True,
        'occurance'			: 1,
        'column-width'		: 13.57
    }, {
        'header'			: 'Top-Proc%',
        'pattern'			: 'PID',
        'field-idx'			: 8,
        'next-line'			: True,
        'occurance'			: 1,
        'type'				: 'int',
        'column-width'		: 11.57
    }
]


def get_workbook_name(filename):
    global configs

    workbook_name = 'results.xlsx'
    for f in configs:
        if f in filename:
            workbook_name = 'results_%s.xlsx' % f
            return workbook_name


def get_worksheet_name(filename):
    global tests

    for t in tests:
        if t in filename:
            return t
    return tests[0]


def close_workbooks():
    global workbooks

    for workbook_name, workbook in workbooks.items():
        workbook.close()


def get_workbook(filename):
    global configs
    global workbooks

    workbook_name = get_workbook_name(filename)
    log.debug('Getting workbook [%s]' % workbook_name)

    if workbook_name not in workbooks:
        log.debug('Initializing workbook [%s]' % workbook_name)
        workbooks[workbook_name] = xlsx.Workbook('./%s' % workbook_name)
        return workbooks[workbook_name]


def get_worksheet(filename):
    global tests
    global worksheets

    workbook = get_workbook(filename)
    workbook_name = get_workbook_name(filename)
    worksheet_name = get_worksheet_name(filename)
    worksheet_pattern = '%s - %s' % (workbook_name, worksheet_name)
    log.debug('Getting worksheet [%s]' % worksheet_pattern)

    if worksheet_pattern not in worksheets:
        log.debug('Adding worksheet [%s] to workbook [%s]' % (worksheet_name, workbook_name))
        worksheets[worksheet_pattern] = workbook.add_worksheet(worksheet_name)
        return worksheets[worksheet_pattern]


def write_value(filename, col, row, value):
    worksheet = get_worksheet(filename)

    log.debug('writing (%d, %d) as [%s]' % (col, row, value))
    worksheet.write(col, row, value)


def examine_file(filename, sample):
    global sections
    global search_data

    top_instance = 0
    previous_line = ''

    try:
        fp = open(filename, 'r')

        for line in fp:
            line = line.rstrip()
            log.debug('Examining line:[%s]' % line)

            # if we found a match, count the number of matches
            # the 'Tasks' output starts on the second line of the
            # 'top' output and helps us identify the start of a new
            # output block of the 'top' command
            if line.startswith('Tasks'):
                top_instance += 1

            for search_idx, search in enumerate(search_data):
                if 'next-line' in search and search['next-line']:
                    search_line = previous_line
                    extract_line = line
                else:
                    search_line = line
                    extract_line = line
                    search_fields = search_line.split()
                    search_field_idx = 0
                    search_field = ''
                    extract_fields = extract_line.split()
                    extract_field_idx = 0
                    extract_field = ''

                header = search['header']
                pattern = search['pattern']

                if 'position' in search:
                    # If position specified, only check that search_field
                    if len(search_fields) <= search['position']:
                        continue
                    search_field_idx = search['position']
                    search_field = search_fields[search_field_idx]
                    if pattern not in search_fields[search_field_idx]:
                        continue
                    else:
                        # Else look for the pattern anywhere in the line
                        if pattern not in search_line:
                            continue
                    for search_field_idx, search_field in enumerate(search_fields):
                        if pattern in search_field:
                            break

                # If occurances is specified and equal to the number of matches
                if 'occurance' in search and top_instance != search['occurance']:
                    continue

                # If field-idx is specified, get that field
                if 'field-idx' in search:
                    if len(extract_fields) <= search['field-idx']:
                        log.debug('ignoring line as field count is too short')
                        continue
                    extract_field_idx = search['field-idx']
                    extract_field = extract_fields[extract_field_idx]
                else:
                    extract_field_idx = search_field_idx
                    extract_field = search_fields[search_field_idx]

                # If we are to exclude the pattern, get the remaining portion
                if 'exclude-pattern' in search and search['exclude-pattern']:
                    extract_field = extract_field.replace(pattern, '')

                # Found a match at this point
                log.debug('FOUND MATCH: field:[%s] sample:[%d] pattern:[%s] data:[%s] at [%d] occurance:[%d]'
                          % (header, sample, pattern, extract_field, extract_field_idx, top_instance))

                if 'type' in search and len(extract_field):
                    if search['type'] == 'int':
                        extract_field = int(extract_field)
                    elif search['type'] == 'float':
                        extract_field = float(extract_field)

                row_offset = data_row_offset + sample + 2
                section_offset = 0
                for section_idx, section in enumerate(sections):
                    if section in filename:
                        section_offset = section_idx * (len(search_data) + 1)
                        break
                section_offset += search_idx

                write_value(filename, row_offset, section_offset, extract_field)

            # save previous line for any match patterns that are on the next line
            previous_line = line
    finally:
        fp.close()


def finalize_file(filename, sample_count):
    global sections
    global search_data
    global groups
    global data_row_offset
    global group_row_offset

    workbook = get_workbook(filename)
    workbook_name = get_workbook_name(filename)
    worksheet = get_worksheet(filename)
    worksheet_name = get_worksheet_name(filename)

    log.info('Finalizing data for [%s / %s] samples:[%d]' % (workbook_name, worksheet_name, sample_count))

    for section_idx, section in enumerate(sections):
        if section not in filename:
            continue

        row_offset = data_row_offset
        section_offset = section_idx * (len(search_data) + 1)

        # Write the data header info
        write_value(filename, row_offset, section_offset, "%s" % section.replace('c', '-C'))
        for search_idx, search in enumerate(search_data):

            if 'column-width' in search:
                column_width = search['column-width']
            else:
                column_width = default_column_width
                column = section_offset + search_idx
                worksheet.set_column(column, column, column_width)
                write_value(filename, row_offset + 1, column, search['header'])

        # Write the Group info
        for group_idx, group in enumerate(groups):
            group_offset = group_idx * group_row_offset

            # Add the group name and summary header
            write_value(filename, group_offset, section_offset, "%s %s" % (section.replace('c', '-C'), group))
            write_value(filename, group_offset, section_offset + 1, 'Average')
            write_value(filename, group_offset, section_offset + 2, 'Min')
            write_value(filename, group_offset, section_offset + 3, 'Max')

            # Add group chart
            log.debug('Adding chart [%s / %s] to [%s]' % (section, group, worksheet_name))
            chart = workbook.add_chart({'type': 'line'})

            # Check out field data for any summary / chart membership
            summary_row = 1
            for search_idx, search in enumerate(search_data):
                col_idx = section_offset + search_idx
                col = ''
                col_wrap = 0
                # If the column number is greater than
                while col_idx >= 26:
                    col_idx -= 26
                    col = string.ascii_uppercase[col_wrap]
                    col_wrap += 1
                    col += string.ascii_uppercase[col_idx]

                # Add the chart group series
                if 'chart-group' in search and search['chart-group'] == group_idx:
                    series_name = '=%s!$%s$%d' % (worksheet_name, col, data_row_offset + 2)
                    series_data = '=%s!$%s$%d:$%s$%d' % (worksheet_name, col, data_row_offset + 3,
                                                         col, data_row_offset + sample_count + 2)
                    log.debug('Adding chart series:[%s] data:[%s] to [%s / %s / %s]'
                              % (series_name, series_data, worksheet_name, section, group))
                    chart.add_series({'name': series_name, 'values': series_data})

                # Add the summary group info
                if 'summary-group' in search and search['summary-group'] == group_idx:
                    write_value(filename, group_offset + summary_row, section_offset, search['header'])
                    write_value(filename, group_offset + summary_row, section_offset + 1,
                                '=AVERAGE($%s%d:$%s$%d)' % (col, data_row_offset + 3,
                                                            col, data_row_offset + sample_count + 2))
                    write_value(filename, group_offset + summary_row, section_offset + 2,
                                '=MIN($%s%d:$%s$%d)' % (col, data_row_offset + 3, col,
                                                        data_row_offset + sample_count + 2))

                    write_value(filename, group_offset + summary_row, section_offset + 3,
                                '=MAX($%s%d:$%s$%d)' % (col, data_row_offset + 3, col,
                                                        data_row_offset + sample_count + 2))
                    summary_row += 1

            # Add the chart to the worksheet
            worksheet.insert_chart(group_offset, section_offset + 4, chart,
                                   {'x_scale': default_x_scale,
                                    'y_scale': default_y_scale})


def examine_directory(directory):
    global args
    global terminate

    file_pause = args.pause

    log.debug('Examining directory [%s]' % directory)

    sample_count = 0
    listing = sorted(glob.glob('%s/*_STATS_*' % directory))
    for filename in listing:
        examine_file(filename, sample_count)
        sample_count += 1
        if file_pause:
            response = input("Done with file [%s]. Next/Continue/Break/Stop: " % filename).lower()
            if response in ('n', 'next'):
                continue
            elif response in ('c', 'continue'):
                file_pause = 0
                continue
            elif response in ('b', 'break'):
                break
            elif response in ('s', 'stop'):
                terminate = 1
                return

    if sample_count:
        finalize_file(directory, sample_count)

    if sample_count and args.pause:
        response = input("Done with direcotry [%s] Continue [y/n]: " % directory).lower()
        if response in ('n', 'no'):
            terminate = 1
            return

    for path in os.listdir(directory):
        if terminate:
            return
        if args.recurse:
            if os.path.isdir('%s/%s' % (directory, path)):
                examine_directory('%s/%s' % (directory, path))


def main():
    global args

    directory = args.directory

    logger = log.getLogger()
    if args.verbose:
        logger.setLevel(log.DEBUG)

    # Validate the search data
    search_entries = {}
    for search_idx, search in enumerate(search_data):
        if 'header' not in search:
            log.error('Search data invalid. No header definition at idx [%d]' % search_idx)
            return
        if 'pattern' not in search:
            log.error('Search data invalid. No pattern definition for [%s] at idx [%d]'
                      % (search['header'], search_idx))
            return
        if search['header'] in search_entries:
            log.error('Search Data invalid. Duplicate entry [%s] at idx [%d]'
                      % (search['header'], search_idx))
            return

    log.info('Starting stats analysis...')
    examine_directory(directory)

    log.info('Closing workbooks')
    close_workbooks()


if __name__ == '__main__':
    main()
